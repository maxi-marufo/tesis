\chapter{Estimación Puntual}\label{puntual}

Durante los últimos años, se han propuesto varios métodos de cuantificación
desde diferentes perspectivas y con diferentes objetivos. En términos generales,
se pueden distinguir dos grandes clases de métodos en la literatura. La primera
clase es la de métodos agregativos, es decir, métodos que requieren la
clasificación de todos los individuos como un paso intermedio. Dentro de los
métodos agregativos, se pueden identificar dos subclases. La primera subclase
incluye métodos basados en clasificadores de propósito general; en estos métodos
la clasificación de los elementos individuales realizados como un paso
intermedio puede lograrse mediante cualquier clasificador. La segunda subclase
se compone, en cambio, de métodos que para clasificar los individuos, se basan
en métodos de aprendizaje diseñados con la cuantificación en mente. La segunda
clase es la de métodos no agregativos, es decir, métodos que resuelven la tarea
de cuantificación “holísticamente”, es decir, sin clasificar a los individuos.
La idea de esta tésis no es la de mostrar todos los métodos propuestos hasta la
actualidad, sino la de mencionar a continuación los métodos más populares.

\section{Métodos Agregativos}\label{puntual:agregativos}

\subsection{Con clasificadores generales}

Dentro de los métodos agregativos, algunos de ellos requieren como entrada las
etiquetas de clases predichas (es decir, clasificacores duros), mientras que
otros requieren como entrada las probabilidades {\it a posteriori\/} de
pertenencia a cada clase (es decir, clasificacores blandos)\footnote{Los
clasificadores blandos se pueden convertir en duros usando umbrales de
clasificación}. En estos últimos, además, las probabilidades {\it a
posteriori\/} deben estar calibradas (para mayor información sobre calibración
consultar el Apéndice~\ref{appendix:calibracion}).

\subsubsection{Clasificar y Contar (CC)}

El método más sencillo y directo para construir un cuantificador para
clasificación (tanto binaria como multiclase) es aplicar el enfoque {\it
Classify \& Count\/}~\cite{forman2005counting}. {\it CC\/} juega un papel
importante en la investigación de cuantificación ya que siempre se utiliza como
el {\it baseline\/} que cualquier método de cuantificación razonable debe
mejorar. Este método consiste simplemente en: (i) ajustar un clasificador duro,
y luego (ii), utilizando dicho clasificador, clasificar las instancias de la
muestra de prueba, contando la proporción de cada clase. Generalizando el
estimador de {\it CC\/} para el caso multiclase, el mismo queda entonces
definido por:
\begin{equation}
    \hat p^{CC}_{tst}(c) = \frac{\#\{\boldsymbol{x} \in \boldsymbol{X}_{tst}|h(\boldsymbol{x})=c\}}{\#\boldsymbol{X}_{tst}}\label{ecuacion:cc}
\end{equation}
donde se uso $h$ para la función de decisión del clasificador duro.

Es evidente que podemos obtener un cuantificador perfecto si el clasificador es
también perfecto. El problema es que obtener un clasificador perfecto es casi
imposible en aplicaciones reales, y luego el cuantificador hereda el sesgo del
clasificador. Este aspecto se analiza en varios artículos tanto desde una
perspectiva teórica como práctica, como lo
hizo~\citeauthor{forman2008quantifying}, y como también ya lo hemos mencionado
en~\ref{problema:clasificar_y_contar}.

\subsubsection{Clasificar, Contar y Ajustar (ACC)}

Conocido en inglés como {\it Adjusted Classify \& Count}, {\it Adjusted
Count\/}~\cite{forman2008quantifying} o también como {\it Confusion Matrix
Method\/}~\cite{saerens2002adjusting}, este método se basa en corregir las
estimaciones de {\it CC\/} teniendo en cuenta la tendencia del clasificador a
cometer errores de cierto tipo. Un modelo {\it ACC\/} está compuesto por dos
elementos: un clasificador duro (como en {\it CC\/}) y de las estimaciones de
$tpr$ y $fpr$. Dichas estimaciones pueden obtenerse usando validación cruzada o
{\it cross-validation\/} o un conjunto de validación aparte. Luego, en la fase
de predicción, el modelo obtiene una primera estimación $\hat p$ de la misma
forma que en {\it CC}, que, para el caso binario, luego es ajustado aplicando la
siguiente fórmula\footnote{A veces, esta expresión conduce a un valor inválido
de $\hat p^{ACC}_{tst}$ que debe recortarse en el rango $[0, 1]$ en un último
paso.}:
\begin{equation}
    \hat p^{ACC}_{tst}(c=1) = \frac{\hat p^{CC}_{tst}(c=1)-fpr}{tpr-fpr}\label{ecuacion:acc_binaria}
\end{equation}
Esta expresión se obtiene despejando la verdadera prevalencia $p$ de la
ecuación~\ref{ecuacion:cc}. La prevalencia ajustada $\hat p^{ACC}_{tst}(c)$
depende entonces de la estimación $\hat p^{CC}_{tst}(c)$ dada por {\it CC\/} y
de $tpr$ y $fpr$. Pero como $tpr$ y $fpr$ son desconocidas generalmente, se
utilizan estimaciones.

El método {\it ACC\/} es teóricamente perfecto, independientemente de la métrica
de {\it accuracy\/} obtenida con el clasificador, cuando se cumple el supuesto
de {\it prior probability shift\/}~\ref{problema:cambios} y cuando las
estimaciones de $tpr$ y $fpr$ son perfectas. Desafortunadamente, es raro que se
cumplan ambas condiciones en aplicaciones del mundo real:
$\mathbb{P}(\boldsymbol{X}|Y)$ puede tener variaciones entre los datos de
entrenamiento y los de predicción, y es difícil obtener estimaciones perfectas
para $tpr$ y $fpr$ en algunos dominios ya que suelen haber pequeñas muestras
disponibles y/o están muy desequilibradas. Pero incluso en estos casos, el
rendimiento del método {\it ACC\/} suele ser mejor que el de {\it CC}.

Partiendo de~\ref{ecuacion:cc} y utilizando el teorema de probabilidad total,
podemos extender~\ref{ecuacion:acc_binaria} para el caso multiclase:
\begin{align}
\begin{split}
    \hat p^{CC}_{tst}(c=c_k) &= \mathbb{\hat P}_{tst}(h(\boldsymbol{x})=c_k) \\
    &= \sum \limits_{j=1}^{\#C}{\mathbb{\hat P}(h(\boldsymbol{x})=c_k|y=c_j) \hat p^{ACC}_{tst}(c=c_j)}\label{ecuacion:acc_multiclase}
\end{split}
\end{align}
donde $\hat p^{CC}_{tst}(c=c_k)$ es la fracción de datos de $tst$ que el
clasificador $h$ asigna a $c_k$ (y por ende, es conocido), y $\mathbb{\hat
P}(h(\boldsymbol{x})=c_k|y=c_j)$ es la estimación de probabilidad de que el
clasificador $h$ asigne la clase $c_k$ a $\boldsymbol{x}$ cuando este pertenece
a la clase $c_j$. Estas probabilidades, al igual que $tpr$ y $fpr$ en el caso
binario, deben estimarse mediante validación cruzada o con un conjunto de
validación aparte~\cite{barranquero2013study, forman2005counting,
forman2008quantifying}. Luego, $\hat p^{ACC}_{tst}(c=c_j)$, nuestras incógnitas
(una por cada $c_j$), pueden calcularse mediante un sistema de ecuaciones
lineales con $\#C$ ecuaciones y $\#C$ incógnitas.

\subsubsection{Clasificar y Contar Probabilístico (PCC)}

Este método, conocido en inglés como {\it Probabilistic Classify and
Count\/}~\cite{bella2010quantification, tang2010network}, es una variante de
{\it CC\/} que utiliza un clasificador blando en vez de uno duro. Es decir, que
la salida del clasificador será una estimación de la probabilidad {\it a
posteriori\/} $s(\boldsymbol{x}, y) = \hat
p_{Y|\boldsymbol{X}=\boldsymbol{x}}(y)$ por cada invididuo $\boldsymbol{x} \in
\mathbb{R}^d$ y cada $y \in C$. El método consiste en estimar las $\hat
p_{tst}(c=c_j)$ mediante el valor esperado de la proporción de items que se
predijeron como pertenecientes a cada clase $c_j$:
\begin{align}
\begin{split}
    \hat p^{PCC}_{tst}(c=c_j) &= \mathbb{\hat E}[p_{Y|\boldsymbol{X}=\boldsymbol{x}}(y=c_j)] \\
    &= \frac{1}{m} \sum \limits_{i=1}^{m}{\hat p_{Y|\boldsymbol{X}=\boldsymbol{x}_i}(y=c_j)} \\
    &= \frac{1}{m} \sum \limits_{i=1}^{m}{s(\boldsymbol{x}_i, y=c_j)}
\end{split}
\end{align}
con $m=\#\boldsymbol{X}_{tst}$. La intuición detrás de {\it PCC\/} es que las
probabilidades {\it a posteriori\/} contienen mayor información que las
decisiones de un clasificador duro y, por lo tanto, deberían ser usadas en su
lugar. Sin embargo,~\citet[Corolario 6, p. 157 y p.163]{tasche2014exact}
demuestra que el comportamiento de {\it PCC\/} será similar al de {\it CC}, en
cuanto a que ambos subestiman o sobreestiman la prevalencia verdadera cuando la
distribución de clases cambia entre los datos de entrenamiento y de prueba.

\subsubsection{Clasificar, Contar y Ajustar Probabilístico (PACC)}

Presentado como {\it Probabilistic Adjusted Classify and Count\/} o también como
{\it Probabilistic Adjusted Count}, este método combina las ideas de {\it ACC\/}
y de {\it PCC}.
\begin{align}
\begin{split}
    \hat p^{PCC}_{tst}(c=c_k) &= \mathbb{\hat E}[\mathbb{P}_{tst}(h(\boldsymbol{x})=c_k)] \\
    &= \mathbb{\hat E}[\sum \limits_{j=1}^{\#C}{\mathbb{P}(h(\boldsymbol{x})=c_k|y=c_j) p^{PACC}_{tst}(c=c_j)}] \\
    &= \sum \limits_{j=1}^{\#C}\mathbb{\hat E}[{\mathbb{P}(h(\boldsymbol{x})=c_k|y=c_j) p^{PACC}_{tst}(c=c_j)}] \\
    &= \sum \limits_{j=1}^{\#C}\mathbb{\hat E}[{\mathbb{P}(h(\boldsymbol{x})=c_k|y=c_j)}] \hat p^{PACC}_{tst}(c=c_j) \\
    &= \sum \limits_{j=1}^{\#C} [\frac {1}{\#U_j} \sum_{\boldsymbol{x} \in U_j} \mathbb{\hat P}(h(\boldsymbol{x})=c_k)] \hat p^{PACC}_{tst}(c=c_j)
\end{split}
\end{align}
donde $U_j=\{(\boldsymbol{x}, y) \in (\boldsymbol{X}_{tst}, Y_{tst}) | y=c_j\}$.
Luego, $\hat p^{PCC}_{tst}(c=c_k)$ se calcula mediante {\it PCC\/} y, como en
{\it ACC}, las $[\frac {1}{\#U_j} \sum_{\boldsymbol{x} \in U_j} \mathbb{\hat
P}(h(\boldsymbol{x})=c_k)]$ deben estimarse mediante validación cruzada o con un
conjunto de validación aparte, quedando nuevamente un sistema de ecuaciones
lineales de $\#C$ ecuaciones y $\#C$ incógnitas.

Para el caso particular binario, y relacionando con~\ref{ecuacion:acc_binaria},
tenemos:
\begin{equation}
    \hat p^{PACC}_{tst}(c=1) = \frac{\hat p^{PCC}_{tst}(c=1)-fppa}{tppa-fppa}
\end{equation}

En este método hay que tener en cuenta ambas consideraciones sobre las
estimaciones de $\hat p$ dentro del rango $[0, 1]$ y sobre la calibración
-ver~\ref{appendix:calibracion}-.

\subsubsection{Selección de Umbrales}



\subsection{Con clasificadores específicos}

\section{Métodos No Agregativos}\label{puntual:no_agregativos}
