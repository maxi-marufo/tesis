\chapter{Métodos de Estimación}\label{estimacion}

Durante los últimos años, se han propuesto varios métodos de cuantificación
desde diferentes perspectivas y con diferentes objetivos. En términos generales,
se pueden distinguir dos grandes clases de métodos en la literatura. La primera
clase es la de métodos agregativos, es decir, métodos que requieren la
clasificación de todos los individuos como un paso intermedio. Dentro de los
métodos agregativos, se pueden identificar dos subclases. La primera subclase
incluye métodos basados en clasificadores de propósito general; en estos métodos
la clasificación de los elementos individuales realizados como un paso
intermedio puede lograrse mediante cualquier clasificador. La segunda subclase
se compone, en cambio, de métodos que para clasificar los individuos, se basan
en métodos de aprendizaje diseñados con la cuantificación en mente. La segunda
clase es la de métodos no agregativos, es decir, métodos que resuelven la tarea
de cuantificación “holísticamente”, es decir, sin clasificar a los individuos.
La idea de esta tesis no es la de mostrar todos los métodos propuestos hasta la
actualidad, sino la de mencionar los métodos más populares.

\subsubsection{Caso de Ejemplo}\label{estimacion:ejemplo}

Como ejemplo de muestra para comparar los distintos métodos de estimación, se
usará el mismo set de datos artificiales que en las figuras~\ref{fig:intro}
y~\ref{fig:cambios}. Para crear el set de datos se utilizó el algoritmo
prepuesto por~\citet{Guyon2003DesignOE} mediante la
función~\href{https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html}{{\it
make\_classification}} de {\it scikit-learn}, usando los siguientes parámetros
de entrada:

\begin{python}
population_size = 150 X, y = make_classification( n_samples=population_size,
n_features=2, n_informative=2, n_redundant=0, n_repeated=0,
n_clusters_per_class=2, n_classes=2, weights=None, class_sep=0.1,
random_state=42, )
\end{python}

Esta función, al usar \(weights=None\), crea un set de datos balanceados en
cuanto a las clases de los individuos (figura~\ref{fig:intro}). Sin embargo,
para poder evaluar los distintos métodos, lo que haremos ahora es seleccionar
100 individuos y usarlos como datos de entrenamiento, y hacer un sub-muestreo de
los 50 restantes de forma tal de aproximarnos a un \(p_{tst}=0.1\):

\begin{python}
train_size = 100 prev_test = 0.1 X_train, y_train = X[:train_size],
y[:train_size] X_test, y_test = X[train_size:], y[train_size:]
idx_negatives_test = np.argwhere(y_test==0).flatten() idx_positives_test =
np.random.choice( np.argwhere(y_test==1).flatten(),
size=round((prev_test)*len(idx_negatives_test)/(1-prev_test)), replace=False )
idx_test = np.concatenate([idx_positives_test, idx_negatives_test]) X_test =
X_test[idx_test] y_test = y_test[idx_test]
\end{python}

El código de arriba termina generando un set de entrenamiento de tamaño
\(n_{tr}=100\) con \(p_{tr}=0.53\) (figuras~\ref{cambios:datos_tr}
y~\ref{cambios:prevalencia_tr}) y uno de prueba de tamaño \(n_{tst}=31\) con
\(p_{tst}\approx0.097\) (figuras~\ref{cambios:clasificacion_tst}
y~\ref{cambios:cuantificacion_tst}).

El modelo de clasificación utilizado para generar las predicciones mostradas en
ambas figuras~\ref{fig:intro} (entrenando y prediciendo con todos los datos)
y~\ref{fig:cambios} (entrenando con los datos de entrenamiento y prediciendo los
de prueba) es el clasificador {\it Naive Bayes\/} generado mediante la
clase~\href{https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html}{{\it
GaussianNB}} de {\it scikit-learn}, usando sus parámetros por default.

\section{Métodos Agregativos}\label{estimacion:agregativos}

\subsection{Con clasificadores generales}\label{estimacion:generales}

Dentro de los métodos agregativos, algunos de ellos requieren como entrada las
etiquetas de clases predichas (es decir, el tipo de salida que devuelven los
clasificadores denominados duros), otros requieren un {\it score\/} de decisión
(como podría ser la distancia al hiperplano de separación en el clasificador
SVM), y otros que requieren como entrada las probabilidades {\it a posteriori\/}
de pertenencia a cada clase (es decir, el tipo de salida que devuelven los
clasificadores denominados blandos)\footnote{Los clasificadores blandos y de
{\it score\/} se pueden convertir en duros usando umbrales de clasificación}. En
estos últimos, además, las probabilidades {\it a posteriori\/} deben estar
calibradas (para mayor información sobre calibración consultar el
Apéndice~\ref{appendix:calibracion}). Para estos casos, en los ejemplos a
continuación que requieren clasificadores blandos se separó de las muestras de
entrenamiento un 15\% de datos para el proceso de calibración (y estratificando
para que la proporción de etiquetas se mantenga igual).

\subsubsection{Clasificar y Contar (CC)}\label{estimacion:cc}

El método más sencillo y directo para construir un cuantificador para
clasificación (tanto binaria como multiclase) es aplicar el enfoque {\it
Classify \& Count\/}~\cite{forman2005counting}. {\it CC\/} juega un papel
importante en la investigación de cuantificación ya que siempre se utiliza como
el {\it baseline\/} que cualquier método de cuantificación razonable debe
mejorar. Este método consiste simplemente en: (i) ajustar un clasificador duro,
y luego (ii), utilizando dicho clasificador, clasificar las instancias de la
muestra de prueba, contando la proporción de cada clase. Generalizando el
estimador de {\it CC\/} para el caso multiclase, el mismo queda entonces
definido por:
\begin{equation}
    \hat p^{\it CC\/}_{tst}(c) = \frac{\#\{\boldsymbol{x} \in \boldsymbol{X}_{tst}|h_{tr}(\boldsymbol{x})=c\}}{\#\boldsymbol{X}_{tst}}\label{ecuacion:cc}
\end{equation}
donde se usó \(h_{tr}\) para la función de decisión del clasificador duro
ajustado con la muestra de entrenamiento.

Es evidente que podemos obtener un cuantificador perfecto si el clasificador es
también perfecto. El problema es que obtener un clasificador perfecto es casi
imposible en aplicaciones reales, y luego el cuantificador hereda el sesgo del
clasificador. Este aspecto se analiza en varios artículos tanto desde una
perspectiva teórica como práctica, como lo hizo~\citet{forman2008quantifying}, y
como también ya lo hemos mencionado en~\ref{problema:clasificar_y_contar}.

\paragraph{\it Ejemplo:\/} Para el caso de ejemplo, y manteniendo el
clasificador allí usado, debemos contar la cantidad de predicciones positivas
(rojas) en la figura~\ref{fig:cambios}, y dividirlas por el tamaño de la muestra
de prueba. Es decir, \(\hat p^{\it CC\/}_{tst}(c=1) = \frac{23}{31} \approx
0.742\).

\subsubsection{Clasificar, Contar y Ajustar (ACC)}\label{estimacion:acc}

Conocido en inglés como {\it Adjusted Classify \& Count}, {\it Adjusted
Count\/}~\cite{forman2008quantifying} o también como {\it Confusion Matrix
Method\/}~\cite{saerens2002adjusting}, este método se basa en corregir las
estimaciones de {\it CC\/} teniendo en cuenta la tendencia del clasificador a
cometer errores de cierto tipo. Un modelo {\it ACC\/} está compuesto por dos
elementos: un clasificador duro (como en {\it CC\/}) y de las estimaciones de
\(tpr\) y \(fpr\). Dichas estimaciones pueden obtenerse usando validación
cruzada o {\it cross-validation}, ya sea mediante la técnica de {\it k-folds\/}
o un {\it held-out}. Luego, en la fase de predicción, el modelo obtiene una
primera estimación \(\hat p\) de la misma forma que en {\it CC\/} que luego,
para el caso binario, es ajustado aplicando la siguiente fórmula\footnote{A
veces, esta expresión conduce a un valor inválido de \(\hat p^{\it
ACC\/}_{tst}\) que debe recortarse en el rango \([0, 1]\) en un último paso.}:
\begin{equation}
    \hat p^{\it ACC\/}_{tst}(c=1) = \frac{\hat p^{\it CC\/}_{tst}(c=1)-\hat{fpr}}{\hat{tpr} - \hat{fpr}}\label{ecuacion:acc_binaria}
\end{equation}
Esta expresión se obtiene despejando la verdadera prevalencia \(p\) de la
ecuación~\ref{ecuacion:tpr_fpr} y reemplazando \(fpr\) y \(tpr\) por sus
estimadores.

El método {\it ACC\/} es teóricamente perfecto, independientemente del valor de
{\it accuracy\/} obtenido con el clasificador, cuando se cumple el supuesto de
{\it prior probability shift\/}~\ref{problema:cambios} y cuando las estimaciones
de \(tpr\) y \(fpr\) son perfectas. Desafortunadamente, es raro que se cumplan
ambas condiciones en aplicaciones del mundo real:
\(\mathbb{P}(\boldsymbol{X}|Y)\) puede tener variaciones entre los datos de
entrenamiento y los de predicción, y es difícil obtener estimaciones perfectas
para \(tpr\) y \(fpr\) en algunos dominios ya que suelen haber pequeñas muestras
disponibles y/o están muy desequilibradas. Pero incluso en estos casos, el
rendimiento del método {\it ACC\/} suele ser mejor que el de {\it CC}.

Partiendo de la ecuación~\ref{ecuacion:cc} y utilizando el teorema de
probabilidad total, podemos extender la ecuación~\ref{ecuacion:acc_binaria} para
el caso multiclase:
\begin{align}
\begin{split}
    \hat p^{\it CC\/}_{tst}(c=c_k) &= \mathbb{\hat P}_{tst}(h_{tr}(\boldsymbol{x})=c_k) \\
    &= \sum \limits_{j=1}^{\#C}{\mathbb{\hat P}(h_{tr}(\boldsymbol{x})=c_k|y=c_j) \hat p^{\it ACC\/}_{tst}(c=c_j)}\label{ecuacion:acc_multiclase}
\end{split}
\end{align}
donde \(\hat p^{\it CC\/}_{tst}(c=c_k)\) es la fracción de datos de \(tst\) que
el clasificador \(h\) asigna a \(c_k\) (y por ende, es conocido), y
\(\mathbb{\hat{P}}(h_{tr}(\boldsymbol{x})=c_k|y=c_j)\) es la estimación de
probabilidad de que el clasificador \(h\) asigne la clase \(c_k\) a
\(\boldsymbol{x}\) cuando este pertenece a la clase \(c_j\). Estas
probabilidades, al igual que \(tpr\) y \(fpr\) en el caso binario, deben
estimarse mediante validación cruzada~\cite{barranquero2013study,
forman2005counting, forman2008quantifying}. Luego, \(\hat p^{\it
ACC\/}_{tst}(c=c_j)\), nuestras incógnitas (una por cada \(c_j\)), pueden
calcularse mediante un sistema de ecuaciones lineales con \(\#C\) ecuaciones y
\(\#C\) incógnitas.

\paragraph{\it Ejemplo:\/} Aquí debemos estimar el \(tpr\) y \(fpr\). Para ello,
se separó de la muestra de entrenamiento un 15\% de datos. Con el 85\% de la
muestra se entrenó el clasificador y se obtuvo un \(\hat p^{\it CC\/}_{tst}(c=1)
\approx 0.71\), y con el 15\% separado se obtuvo \(\hat{tpr} \approx 0.625\) y
\(\hat{fpr} \approx 0.714\), y por lo tanto, \(\hat p^{\it ACC\/}_{tst}(c=1)
\approx 0.0516\).

\subsubsection{Clasificar y Contar Probabilístico (PCC)}\label{estimacion:pcc}

Este método, conocido en inglés como {\it Probabilistic Classify and
Count\/}~\cite{bella2010quantification, tang2010network}, es una variante de
{\it CC\/} que utiliza un clasificador blando en vez de uno duro. Es decir, que
la salida del clasificador blando ajustado con la muestra de entrenamiento,
\(s(\boldsymbol{x}, y)\), será una estimación de la probabilidad {\it a
posteriori\/} \({p}_{Y|\boldsymbol{X}=\boldsymbol{x}}(y)\) por cada individuo
\(\boldsymbol{x} \in \boldsymbol{X}_{tst}\) y cada \(y \in C\). El método
consiste en estimar las \({p}_{tst}(c=c_j)\) mediante el valor esperado de la
proporción de items que se predijeron como pertenecientes a cada clase \(c_j\):
\begin{align}
\begin{split}
    \hat p^{\it PCC\/}_{tst}(c=c_j) &= \mathbb{\hat E}[p_{Y|\boldsymbol{X}=\boldsymbol{x}}(y=c_j)] \\
    &= \frac{1}{m} \sum \limits_{i=1}^{m}{\hat p_{Y|\boldsymbol{X}=\boldsymbol{x}_i}(y=c_j)} \\
    &= \frac{1}{m} \sum \limits_{i=1}^{m}{s(\boldsymbol{x}_i, y=c_j)}
\end{split}
\end{align}
con \(m=\#\boldsymbol{X}_{tst}\). La intuición detrás de {\it PCC\/} es que las
probabilidades {\it a posteriori\/} contienen mayor información que las
decisiones de un clasificador duro y, por lo tanto, deberían ser usadas en su
lugar. Sin embargo,~\citet[Corolario 6, p.157 y p.163]{tasche2014exact}
demuestra que el comportamiento de {\it PCC\/} será similar al de {\it CC}, en
cuanto a que ambos subestiman o sobreestiman la prevalencia verdadera cuando la
distribución de clases cambia entre los datos de entrenamiento y de prueba.

\paragraph{\it Ejemplo:\/} Como este método utiliza un clasificador blando, se
separó primero un 15\% de los datos de entrenamiento. Con el 85\% se entrenó el
clasificador, y luego con el 15\% se realizó la calibración. Luego, debemos
sumar las salidas del clasificador calibrado para la clase positiva. Para el
ejemplo, se obtuvieron las siguientes salidas:
\begin{center}
    \begin{tabular}{lrrrrrrrrrrrrrrrrrrrrr}
        \toprule
        \textbf{$s(\boldsymbol{x}_i, y=1)$} & 0.54 & 0.54 & 0.49 & 0.50 & 0.45 &
        0.56 & 0.57 & 0.60 & 0.52 & 0.50 & 0.58 & 0.54 \ldots & 0.49 \\
        \bottomrule
    \end{tabular}
\end{center}
siendo \(\hat p^{\it PCC\/}_{tst}(c=1) \approx 0.527\).

\subsubsection{Clasificar, Contar y Ajustar Probabilístico
(PACC)}\label{estimacion:pacc}

Presentado como {\it Probabilistic Adjusted Classify and Count\/} o también como
{\it Probabilistic Adjusted Count}, este método combina las ideas de {\it ACC\/}
y de {\it PCC\/}~\cite{bella2010quantification, tang2010network}.
\begin{align}
\begin{split}
    \hat p^{\it PCC\/}_{tst}(c=c_k) &= \mathbb{\hat E}[\mathbb{P}_{tst}(h_{tr}(\boldsymbol{x})=c_k)] \\
    &= \mathbb{\hat E}[\sum \limits_{j=1}^{\#C}{\mathbb{P}(h_{tr}(\boldsymbol{x})=c_k|y=c_j) p^{\it PACC\/}_{tst}(c=c_j)}] \\
    &= \sum \limits_{j=1}^{\#C}\mathbb{\hat E}[{\mathbb{P}(h_{tr}(\boldsymbol{x})=c_k|y=c_j) p^{\it PACC\/}_{tst}(c=c_j)}] \\
    &= \sum \limits_{j=1}^{\#C}\mathbb{\hat E}[{\mathbb{P}(h_{tr}(\boldsymbol{x})=c_k|y=c_j)}] \hat p^{\it PACC\/}_{tst}(c=c_j) \\
    &= \sum \limits_{j=1}^{\#C} [\frac {1}{\#U_j} \sum_{\boldsymbol{x} \in U_j} \mathbb{\hat P}(h_{tr}(\boldsymbol{x})=c_k)] \hat p^{\it PACC\/}_{tst}(c=c_j)
\end{split}
\end{align}
donde \(U_j=\{(\boldsymbol{x}, y) \in (\boldsymbol{X}_{tst}, Y_{tst}) |
y=c_j\}\). Luego, \(\hat p^{\it PCC\/}_{tst}(c=c_k)\) se calcula mediante {\it
PCC\/} y, como en {\it ACC}, las \([\frac {1}{\#U_j} \sum_{\boldsymbol{x} \in
U_j} \mathbb{\hat{P}}(h_{tr}(\boldsymbol{x})=c_k)]\) deben estimarse mediante
validación cruzada, quedando nuevamente un sistema de ecuaciones lineales de
\(\#C\) ecuaciones y \(\#C\) incógnitas.

Para el caso particular binario, y relacionando con la
ecuación~\ref{ecuacion:acc_binaria}, tenemos:
\begin{equation}
    \hat p^{\it PACC\/}_{tst}(c=1) = \frac{\hat p^{\it PCC\/}_{tst}(c=1)-\hat{fp_{pa}}}{\hat{tp_{pa}}-\hat{fp_{pa}}}
\end{equation}

donde \(tp_{pa}\) y \(fp_{pa}\) ($pa$: {\it probability average\/}) son los dos
parámetros propios del cuantificador a estimar mediante validación cruzada,
siendo \(tp_{pa}\) el promedio de las probabilidades {\it a posteriori\/} para
la clase positiva estimadas por el clasificador correspondientes a los
individuos cuya etiqueta es positiva, y del mismo modo \(fp_{pa}\) pero para
individuos con etiqueta negativa. En este método hay que tener en cuenta ambas
consideraciones sobre las estimaciones de \(\hat p\) dentro del rango \([0, 1]\)
y sobre la calibración -ver~\ref{appendix:calibracion}-.

\paragraph{\it Ejemplo:\/} Del mismo modo que para el ejemplo de {\it PCC}, se
separó de la muestra de entrenamiento un 15\% de datos para realizar la
calibración del clasificador blando. Pero también se separó otro 15\% para
realizar el ajuste del propio método de cuantificación. Con el 70\% de datos se
entrenó el clasificador que luego fue calibrado usando el primer 15\% separado,
obteniendo un \(\hat p^{\it PCC\/}_{tst}(c=1) \approx 0.51\). Luego, con el
segundo 15\% de datos, se procedió a estimar \(tp_{pa}\) y \(fp_{pa}\). Teniendo
en cuenta entonces ahora tanto las salidas del clasificador calibrado como las
etiquetas de la muestra, tenemos:
\begin{center}
    \begin{tabular}{ccc}
        \toprule
        \(s(\boldsymbol{x}_i, y=0)\) &  \(s(\boldsymbol{x}_i, y=1)\) & \(c\) \\
        \midrule
        0.23 &    0.77 &  1 \\
        0.78 &    0.22 &  0 \\
        0.40 &    0.60 &  1 \\
        0.43 &    0.57 &  1 \\
        0.32 &    0.68 &  1 \\
        \ldots              \\
        0.58 &    0.42 &  0 \\
     \bottomrule
        \bottomrule
        \end{tabular}
\end{center}

siendo entonces \(\hat{tp_{pa}} \approx 0.551\) y \(\hat{fp_{pa}} \approx
0.548\), por lo que \(\hat p^{\it PACC\/}_{tst}(c=1) \approx 1.00\) (teniendo
que haber truncado).

\subsubsection{Selección de Umbrales (TH)}\label{estimacion:umbrales}

Cuando los datos de entrenamiento presentan un desbalance significativo
(generalmente los casos positivos son los escasos), la precisión de {\it ACC\/}
se ve considerablemente afectada~\cite{forman2006quantifying}. En estas
situaciones, el clasificador tiende a favorecer la predicción de la clase
mayoritaria (negativa), lo que disminuye la cantidad de \(fp\) pero a expensas
de un bajo \(tpr\). Esto se traduce en un denominador reducido en la
ecuación~\ref{ecuacion:acc_binaria}, lo que hace que el método sea más sensible
a las estimaciones de \(tpr\) y \(fpr\).

Esta serie de métodos se fundamenta en la elección de un umbral que reduzca la
varianza en las estimaciones de \(tpr\) y \(fpr\). La premisa es identificar un
umbral que aumente el número de \(tp\), aunque generalmente esto conlleve un
incremento \(fpr\). Siempre que \(tpr \gg fpr\), el denominador
en~\ref{ecuacion:acc_binaria} aumenta, lo que resulta en métodos más robustos
ante pequeños errores en las estimaciones de \(tpr\) y \(fpr\). Siguiendo esta
lógica,~\citet{forman2006quantifying, forman2008quantifying} propone una serie
de métodos basados en clasificadores que entreguen {\it scores\/} (no
necesariamente probabilísticos ni calibrados) con distintas estrategias de
selección de umbrales\footnote{Los métodos aquí se describen son exclusivamente
de cuantificación binaria (las versiones multiclase no han sido abordadas en la
literatura y no son sencillas de implementar)}:

\begin{itemize}
    \item MAX:\@ selecciona el umbral que maximiza \(tpr-fpr\). Esto resulta en
    el mayor denominador posible en la ecuación~\ref{ecuacion:acc_binaria} para
    el clasificador entrenado, lo que suaviza las correcciones.
    \item X:\@ busca obtener \(fpr=1-tpr\) para evitar los extremos de ambas
    curvas.
    \item T50:\@ elige el umbral con \(tpr=0.5\), asumiendo que los positivos
    conforman la clase minoritaria. El objetivo es nuevamente evitar los
    extremos de la curva \(tpr\).
    \item Median Sweep (MS):\@ adopta un enfoque conjunto, calculando la
    prevalencia para todos los umbrales que modifiquen los posibles valores de
    \(fpr\) y \(tpr\), y devolviendo la mediana de estas prevalencias como la
    predicción final.
\end{itemize}

\paragraph{\it Ejemplo:\/} En la siguiente figura se visualiza la selección de
umbral según los criterios MAX, X y T50. Con estos umbrales, se computa luego la
etapa de clasificación y, utilizando los correspondientes \(fpr\) y \(tpr\), se
utiliza la ecuación~\ref{ecuacion:acc_binaria}:
\begin{figure}[H]
    \includegraphics[width=\textwidth]{../plots_teoria/seleccion_umbrales_max_x_t50.png}
    \caption{}\label{fig:seleccion_umbrales_max_x_t50}
\end{figure}
Para el criterio MS, en cambio, por cada umbral que cambie \(fpr\) o \(tpr\) se
calcula una prevalencia (se descartan los casos indeterminados
por~\ref{ecuacion:acc_binaria}), y luego la mediana de todas ellas será la
predicción final del método.
\begin{figure}[H]
    \centerline{\includegraphics[width=0.75\textwidth]{../plots_teoria/seleccion_umbrales_ms.png}}
    \caption{}\label{fig:seleccion_umbrales_ms}
\end{figure}
Los resultados obtenidos fueron:
\begin{itemize}
    \item \(\hat p^{MAX}_{tst}(c=1) \approx  0.774\)
    \item \(\hat p^{X}_{tst}(c=1) \approx  0.282\)
    \item \(\hat p^{T50}_{tst}(c=1) \approx  0.282\)
    \item \(\hat p^{MS}_{tst}(c=1) \approx  0.433\)
\end{itemize}

\subsubsection{Esperanza-Maximización (EMQ)}\label{estimacion:emq}

Aunque este método se propuso originalmente para mejorar las probabilidades {\it
a posteriori\/} de modelos de clasificación bajo {\it dataset shift\/}
(ver~\ref{problema:cambios}), el mismo también sirve para mejorar la estimación
de prevalencias. También conocido como {\it SLD\/} por las iniciales de sus
autores, este método fue propuesto por~\citet{saerens2002adjusting} y aplica el
algoritmo de Esperanza-Maximización (EM)~\cite{dempster1977maximum}, un conocido
algoritmo iterativo para encontrar estimaciones de máxima verosimilitud de
parámetros (los valores de prevalencia de clase) para modelos que dependen de
variables no observadas (las etiquetas de clase). Esencialmente, {\it EMQ\/}
actualiza incrementalmente las probabilidades {\it a posteriori\/} utilizando
los valores de prevalencia de clases calculados en el último paso de la
iteración, y actualiza los valores de prevalencia de clases utilizando las
probabilidades {\it a posteriori\/} calculadas en el último paso de la
iteración, de forma mutuamente recursiva, y tomando como punto de partida un
valor determinado para la prevalencia de clases (generalmente el valor
correspondiente a la muestra de entrenamiento o una estimación {\it a priori\/}
dada por algún conocimiento de la muestra de prueba, aunque puede ser cualquier
otro valor), y repitiendo las iteraciones hasta alcanzar la convergencia.

\citet[Apéndice, p.23 a p.25]{saerens2002adjusting} demuestra, mediante el
Teorema de Bayes y el Teorema de probabilidad total, que el algoritmo de EM
aplicado a este problema resulta en los siguientes pasos (el paso 0 se aplica
una sola vez, luego se iteran el E y M):

\begin{enumerate}[leftmargin=*, labelindent=16pt]

    \item[\bf{0 -}] Inicialización de \(\hat p^{(0)}_{Y}(y=c_k)\), generalmente
    haciendo \(\hat p^{(0)}_{Y}(y=c_k) = \hat p_{tr}(c=c_k)\)

    \item[\bf{E -}] Esperanza: \hspace*{\fill}\makebox[4.5in][l]{\(\hat
    p^{(s)}_{Y|\boldsymbol{X}=\boldsymbol{x}_i}(y=c_k) = \dfrac{\dfrac{\hat
    p^{(s)}_{Y}(y=c_k)}{\hat p_{tr}(c=c_k)}s(\boldsymbol{x}_i, y=c_k)}{\sum
    \limits_{j=1}^{\#C} \dfrac{\hat p^{(s)}_{Y}(y=c_j)}{\hat
    p_{tr}(c=c_j)}s(\boldsymbol{x}_i, y=c_k)}\)}

    \item[\bf{M -}] Maximización: \hspace*{\fill}\makebox[4.5in][l]{\(\hat
    p^{(s+1)}_{Y}(y=c_k)=\dfrac{1}{m}\sum \limits_{i=1}^{m}\hat
    p^{(s)}_{Y|\boldsymbol{X}=\boldsymbol{x}_i}(y=c_k)\)}

\end{enumerate}

Finalmente, cuando se alcanza la convergencia, se obtiene: \(\hat p^{\it EMQ
\/}_{tst}(c=c_k) = \hat p_{Y}(y=c_k)\).

Aunque ya mencionamos que el modelo supone que las probabilidades {\it a
posteriori\/} de modelos de clasificación ya están calibradas, se ha estudiado
también que el método {\it EMQ\/} mejora las predicciones de cuantificación si
el clasificador utilizado está calibrado~\cite{esuli2020critical,
alexandari2020maximum}.

\paragraph{\it Ejemplo:\/} Comenzamos con la inicialización, dando en nuestro
caso como resultado \(\hat p^{(0)}_{Y}(y=1) = \hat p_{tr}(c=1) = 0.5\) y \(\hat
p^{(0)}_{Y}(y=0) = \hat p_{tr}(c=0) = 0.5\). En la primera iteración, para el
paso E queda \(\hat p^{(s=0)}_{Y|\boldsymbol{X}=\boldsymbol{x}_i}(y=c_k) =
s(\boldsymbol{x}_i, y=c_k)\) es decir, las mismas salidas del clasificador
calibrado. Luego, para el paso M, y al igual que en {\it PCC}, debemos promediar
cada salida individual del clasificador calibrado por cada una de las clases
existentes, quedando en nuestro caso \(\hat p^{(s=1)}_{Y}(y=1) = p^{\it
PCC\/}_{tst}(c=1) \approx 0.527\). Ahora, en el paso E de la segunda iteración,
se usará este último valor junto con los valores de prevalencia de la muestra de
entrenamiento para ajustar las salidas del clasificador calibrado. Por ejemplo,
para ajustar la salida del primer individuo correspondiente a la clase positiva,
sería: \(\hat p^{(s=1)}_{Y|\boldsymbol{X}=\boldsymbol{x}_i}(y=1) \approx
\dfrac{\dfrac{0.527}{0.5}0.539}{\dfrac{0.527}{0.5}0.539+\dfrac{0.473}{0.5}0.461}\).
Si continuamos repitiendo los pasos E y M de forma sucesiva, y definiendo un
criterio de corte para la convergencia (ya sea por máxima cantidad de
iteraciones o por un umbral de diferencia entre \(\hat p^{(s)}_{Y}(y=c_k)\) y
\(\hat p^{(s+1)}_{Y}(y=c_k)\)), se obtuvo \(p^{\it EMQ \/}_{tst}(c=1) \approx
0.164\).

\subsubsection{Usando la distancia de Hellinger en \(y\)
(HDy)}\label{estimacion:hdy}

\citet{gonzalez2013class} proponen dos métodos fundamentados en la comparación
de distribuciones. Aunque difieren en la manera de representar estas
distribuciones, ambos comparten un elemento esencial: emplean la distancia de
Hellinger como medida para cuantificar la disparidad entre ellas. El primer
método, conocido como {\it HDy}, es un método agregativo ya que emplea las
salidas del clasificador para describir las distribuciones tanto de la muestra
de entrenamiento como la de prueba. El método se basa en el cálculo de:
\begin{equation}\label{ecuacion:hdy}
    p^{\it HDy \/}_{tst}(c=1) = \argmin_{0 \leq \alpha \leq 1}{\text{HD}}(\alpha f_{tr}{(s(\boldsymbol{x},y=1|c=1))}+(1-\alpha) f_{tr}{(s(\boldsymbol{x},y=1|c=0))}, f_{tst}{(s(\boldsymbol{x},y=1))})
\end{equation}
donde:
\begin{equation}\label{ecuacion:hd}
    {\text{HD}}(P \parallel Q)= \frac{1}{\sqrt{2}}{\sqrt {\sum _{i=1}^{k}{({\sqrt {p_{i}}}-{\sqrt {q_{i}}})}^{2}}} \text{ con } P=(p_1,\dots,p_k), Q=(q_1,\dots,q_k)
\end{equation}
y \(f_{tr}(s)\) y \(f_{tst}(s)\) son las funciones de densidad de probabilidad
de las salidas del clasificador para la muestra de entrenamiento y de
evaluación, respectivamente. Estas densidades son aproximadas empíricamente
mediante histogramas, siendo \(k\) el número de {\it bins\/} utilizados. Dado
que el número de {\it bins\/} \(k\) podría tener un impacto significativo en la
estimación, normalmente se utiliza como estimador la mediana de la distribución
de los \(\alpha\) encontrados para un rango de \(k\).

El segundo método propuesto por~\citet{gonzalez2013class} pertenece a los
métodos no agregativos y será desarrollado en la correspondiente
sección~\ref{estimacion:no_agregativos}.

\paragraph{\it Ejemplo:\/} En las siguientes gráficas vemos cómo son las
estimaciones de tres distribuciones estimadas para el ejemplo, la gráfica de la
función de costo usada, y cómo el mínimo encontrado se usa para combinar las
distribuciones de entrenamiento y compararlas con la de prueba. En este caso, se
utilizó sólo \(k=200\).

\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../plots_teoria/hdy_1.png}
    \end{subfigure}
    \begin{subfigure}[b]{0.4\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../plots_teoria/hdy_2.png}
    \end{subfigure}
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../plots_teoria/hdy_3.png}
    \end{subfigure}
    \hfill
\end{figure}

Se observa que el valor mínimo de HDy se da en \(p^{\it HDy \/}_{tst}(c=1) =
0.87\).

\subsection{Con clasificadores específicos}\label{estimacion:especificos}

Los métodos presentados anteriormente implican el uso de un clasificador, a
menudo seguido por una fase de ajuste para contrarrestar cualquier tendencia del
clasificador a subestimar o sobreestimar las proporciones de clases. Los
algoritmos discutidos en esta sección están específicamente diseñados con este
propósito en mente: durante el entrenamiento, tienen en cuenta que el modelo
será utilizado para cuantificar.

\subsubsection{Minimización de pérdida explícita (ELM)}\label{estimacion:elm}

Esta familia de métodos se aplican en principio a la cuantificación binaria,
pero son fácilmente extensibles a la cuantificación multiclase. La idea
propuesta por Esuli y Sebastiani~\cite{esuli2010sentiment} es seleccionar una
medida de rendimiento de cuantificación y entrenar un algoritmo de optimización
para construir el modelo óptimo según esa medida. Las diferencias entre ellos se
deben a la medida de rendimiento seleccionada y al algoritmo de optimización
utilizado.

Esuli y Sebastiani~\cite{esuli2010sentiment, esuli2014explicit,
esuli2015optimizing} proponen utilizar \({\it SVM
\/}_{perf}\)~\cite{joachims2005support} para optimizar la divergencia KL
-ver~\ref{evaluacion:dkl}-, mientras que~\citet{barranquero2015quantification}
también emplean \({\it SVM \/}_{perf}\) pero con una pérdida diferente,
argumentando que la cuantificación pura no considera la precisión del
clasificador subyacente (pudiendo generar un modelo que, aunque cuantifique
bien, clasifique mal). Para abordar esto, introducen la medida \(Q\), que
combina una evaluación de cuantificación con una evaluación de clasificación,
permitiendo un equilibrio entre ellas. Más recientemente Moreo y
Sebastiani~\cite{moreo2021re} reincorporaran la idea de utilizar \({\it SVM
\/}_{perf}\), pero sugieren usar las medidas de evaluación de error absoluto
(AE) y error absoluto negativo (RAE) -ver~\ref{evaluacion:ae}-.

Existen dos inconvenientes asociados con \({\it SVM \/}_{perf}\): podría
resultar en un modelo menos óptimo y no escala para grandes cantidades de datos
de entrenamiento. Para abordar estas limitaciones,~\citet{kar2016online}
proponen algoritmos de optimización estocástica. Además, plantean distintas
medidas multivariadas para evaluar el rendimiento de cuantificación. Siguiendo
esta línea,~\citet{sanyal2018optimizing} introducen una serie de algoritmos que
permiten el entrenamiento directo de redes neuronales profundas y la generación
de clasificadores no lineales. Estos métodos están diseñados para optimizar
funciones de pérdida de cuantificación como la divergencia KL.\@

\paragraph{\it Ejemplo:\/} A diferencia de los casos anteriores, aquí no usamos
el mismo clasificador con el que veníamos trabajando. En cambio, se ajusta un
nuevo clasificador pero con una función de pérdida más acorde al problema de
cuantificación. A modo de ejemplo, usaremos el método propuesto
por~\citet{esuli2010sentiment}, es decir, usando la divergencia KL como pérdida
y \({\it SVM \/}_{perf}\) como algoritmo de optimización. De esta forma,
obtuvimos un \(p^{{\it SVM \/}_{perf}, {\it KLD \/}}_{tst}(c=1) \approx 0.613\),
lo cual efectivamente implica una mejora del KLD con respecto a usar el
clasificador anterior con {\it CC}, ya que \({\it KLD \/}^{\it CC\/}_{tst}
\approx 0.887\) y \({\it KLD \/}^{{\it SVM \/}_{perf}, {\it KLD \/}}_{tst}
\approx 0.556\).

\section{Métodos No Agregativos}\label{estimacion:no_agregativos}

Hasta ahora, hemos utilizado métodos que agregan predicciones individuales de un
clasificador para poder cuantificar. Sin embargo, también es posible estimar
valores de prevalencia de clase sin generar decisiones binarias o probabilidades
{\it a posteriori\/} para cada ítem. Esta alternativa se fundamenta en el
principio de Vapnik, que sugiere resolver problemas directamente con la
información disponible en lugar de abordar un problema más general. En
cuantificación, esto significa que podemos estimar prevalencias de clase
directamente sin clasificar cada individuo.

\subsubsection{Usando la distancia de Hellinger en \(\boldsymbol{x}\)
(HDx)}\label{estimacion:hdx}

Este método está obviamente relacionado con {\it HDy\/} (\ref{estimacion:hdy}),
con la diferencia de considerar distribuciones de probabilidad
multidimensionales \(f(\boldsymbol{x})\) en lugar de distribuciones
unidimensionales \(f(s(\boldsymbol{x}))\). En vez de utilizar las salidas del
clasificador, se estiman, con los datos de entrenamiento, las funciones densidad
de las características de los individuos condicionadas a sus etiquetas.

Debido a la multidimensionalidad de \(\boldsymbol{x} \in
\mathbb{R}^d\),~\citet{gonzalez2013class} proponen minimizar el promedio de las
divergencias de Hellinger por cada \(\boldsymbol{x}^j\):

\begin{equation}\label{ecuacion:hdx}
    p^{\it HDx \/}_{tst}(c=1) = \argmin_{0 \leq \alpha \leq 1}{\frac{1}{d}\sum \limits_{j=1}^{d} \text{HD}}(\alpha f_{tr}({\boldsymbol{x^j}|c=1})+(1-\alpha) f_{tr}({\boldsymbol{x^j}|c=0}), f_{tst}({\boldsymbol{x^j}}))
\end{equation}

\paragraph{\it Ejemplo:\/} Repetimos el tipo de gráficos mostrados para  caso de
{\it HDy}, siendo en este caso \(k=10\).

\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../plots_teoria/hdx_1.png}
    \end{subfigure}
    \begin{subfigure}[b]{0.4\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../plots_teoria/hdx_2.png}
    \end{subfigure}
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../plots_teoria/hdx_3.png}
    \end{subfigure}
    \hfill
\end{figure}

Se observa que el valor mínimo de HDx se da en \(p^{\it HDx \/}_{tst}(c=1) =
0.7\).

\subsubsection{Usando modelos generativos}\label{estimacion:generativos}

\citet{keith2018uncertainty} presentan un enfoque con modelos generativos para
estimar la prevalencia. Este método realiza una inferencia directa de la
prevalencia desconocida y aborda además el cálculo de intervalos de
confianza\footnote{Este enfoque es pionero en la cuantificación, ya que
introduce un modelo directo para el cálculo de los intervalos de confianza, los
cuales eran estimados mediante {\it bootstraping\/} en trabajos anteriores}.

Su propuesta, inspirada también en~\citet{saerens2002adjusting}, se basa en
modelar la distribución conjunta de las características de los individuos y sus
etiquetas. En base a esto se computa la verosimilitud marginal sobre \(\theta\)
para obtener la distribución {\it a posteriori\/} de \(\theta\):

\begin{equation}\label{ecuacion:mll_1}
    {\it MLL\/}(\theta) = \sum \limits_{i=1}^{m} {\log \sum_{c \in C}{p_{\boldsymbol{X}, Y | \theta}(\boldsymbol{x}_i, c)}}
\end{equation}
siendo para el caso binario:
\begin{equation}\label{ecuacion:mll_2}
    {\it MLL\/}(\theta) = \sum \limits_{i=1}^{m} {\log (p_{\boldsymbol{X}, Y | \theta}(\boldsymbol{x}_i, 1) + p_{\boldsymbol{X}, Y | \theta}(\boldsymbol{x}_i, 0))}
\end{equation}
y usando la Ley de Probabilidad Condicionada con \(p_{Y | \theta}(1)= \theta\) y
\(p_{Y | \theta}(0)= 1 - \theta\):
\begin{equation}\label{ecuacion:mll_3}
    {\it MLL\/}(\theta) = \sum \limits_{i=1}^{m} {\log ({{\theta} p_{\boldsymbol{X} | {Y=1,\theta}}(\boldsymbol{x}_i) + (1- \theta) p_{\boldsymbol{X} | {Y=0,\theta}}(\boldsymbol{x}_i)})}
\end{equation}
y como se asume $X_i \perp \!\!\! \perp \theta \mid Y_i$, entonces:
\begin{equation}\label{ecuacion:mll_fin}
    {\it MLL\/}(\theta) = \sum \limits_{i=1}^{m} {\log ({{\theta} p_{\boldsymbol{X} | {Y=1}}(\boldsymbol{x}_i) + (1- \theta) p_{\boldsymbol{X} | {Y=0}}(\boldsymbol{x}_i)})}
\end{equation}
donde se aplica el supuesto de {\it prior probability shift}, es decir,
$\mathbb{P}_{tr}(\boldsymbol{X}=\boldsymbol{x}|Y=y) =
\mathbb{P}_{tst}(\boldsymbol{X}=\boldsymbol{x}|Y=y)$, utilizando las
distribuciones modeladas con los datos de entrenamiento para aplicarlas a los
datos de prueba.

Luego, para obtener la predicción se obtiene el máximo de la distribución. Es
decir, que al igual que el método {\it EMQ}, se busca maximizar la
verosimilitud, pero en este caso no necesariamente utilizando el algoritmo {\it
EM}. Esta función es unimodal en \(\theta \in [0,1]\). Como es cóncava y hay un
sólo parámetro, se pueden emplear muchas técnicas para encontrar la moda,
incluyendo {\it EM}, Newton-Rapshon o computacionalmente mediante una grilla de
valores.

\citet{keith2018uncertainty} proponen particularmente dos modelos generativos
enfocados en problemas de procesamiento de lenguaje ({\it MNB\/ y \it
Loglin\/}), al que llaman explícitos. Pero aún más interesante es el tercer
método que proponen, al que llaman {\it LR-Implicit}, el cual se basa en estimar
de forma implícita las \(p_{\boldsymbol{X}|Y=y}(\boldsymbol{x})\) que
obtendríamos con modelos generativos mediante las
\(p_{Y|\boldsymbol{X}=\boldsymbol{x}}(y)\) que se obtienen con modelos
discriminativos, utilizando el Teorema de Bayes:

\begin{equation}\label{ecuacion:disc_gen}
    {p_{disc}}_{Y|\boldsymbol{X}=\boldsymbol{x}}(y) = \frac{{p_{imp}}_{\boldsymbol{X}|Y=y}(\boldsymbol{x}){p_{tr}}_Y(y)}{p_{\boldsymbol{X}}(\boldsymbol{x})}
\end{equation}

Siendo
\({p_{disc}}_{Y|\boldsymbol{X}=\boldsymbol{x}}(1)=h_{tr}(\boldsymbol{x})\),
entonces podemos utilizar en~\ref{ecuacion:mll_fin}:

\begin{align}\label{ecuacion:disc_gen_2}
\begin{split}
    {\it MLL\/}(\theta) &= \sum \limits_{i=1}^{m} {\log \left( {{\theta} \frac{h_{tr}(\boldsymbol{x}) p_{\boldsymbol{X}}(\boldsymbol{x}_i)}{{p_{tr}}_Y(1)} + (1- \theta) \frac{(1 - h_{tr}(\boldsymbol{x})) p_{\boldsymbol{X}}(\boldsymbol{x}_i)}{{1 - p_{tr}}_Y(1)}} \right)} \\
    &= \sum \limits_{i=1}^{m} {\log \left( p_{\boldsymbol{X}}(\boldsymbol{x}_i) \left( \theta \frac{h_{tr}(\boldsymbol{x})}{{p_{tr}}_Y(1)} + (1- \theta) \frac{(1 - h_{tr}(\boldsymbol{x}))}{({1 - p_{tr}}_Y(1))} \right) \right)} \\
    &= \sum \limits_{i=1}^{m} {\log (p_{\boldsymbol{X}}(\boldsymbol{x}_i))} + \sum \limits_{i=1}^{m} {\log \left( \theta \frac{h_{tr}(\boldsymbol{x})}{{p_{tr}}_Y(1)} + (1- \theta) \frac{(1 - h_{tr}(\boldsymbol{x}))}{({1 - p_{tr}}_Y(1))} \right)} \\
\end{split}
\end{align}
donde para obtener el \(\theta\) que maximiza la función, basta con analizar el
segundo término de la ecuación.

Un modelo generativo que utiliza un clasificador discriminativo como
intermediario para estimar \(p_{\boldsymbol{X}|Y=y}(\boldsymbol{x})\) a partir
de \(p_{Y|\boldsymbol{X}=\boldsymbol{x}}(y)\) (es decir, el método {\it
LR-Implicit\/}) pertenece en realidad a los métodos agregativos (mencionados en
la Sección~\ref{estimacion:agregativos}). No obstante, dado que el marco
generativo presentado por~\citet{keith2018uncertainty} solo requiere un modelo
condicionado por las etiquetas de clase, como ocurre con las versiones
explícitas (usando los modelos {\it MNB\/ y \it Loglin\/} como ejemplo),
enmarcamos este método más general dentro de los métodos no agregativos.

\paragraph{\it Ejemplo:\/} En este caso utilizaremos el método {\it LR-Implicit}
aplicado al clasificador con el que venimos trabajando. Utilizaremos el método
de grilla para buscar el máximo de la curva de \({\it MLL\/}(\theta)\):
\begin{figure}[H]
    \centerline{\includegraphics[width=0.5\textwidth]{../plots_teoria/lr_implicit.png}}
    \caption{}\label{fig:lr_implicit}
\end{figure}

Se observa que el valor mínimo de {\it LR-Implicit} se da en \(p^{\it
LR-Implicit \/}_{tst}(c=1) = 0.14\).
